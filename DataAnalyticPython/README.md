# Scientific computing tools for Python (Just Python no Spark!)
SciPy refers to several related but distinct entities:

* The SciPy ecosystem, a collection of open source software for scientific computing in Python.
* The community of people who use and develop this stack.
* Several conferences dedicated to scientific computing in Python - SciPy, EuroSciPy, and SciPy.in.
* The SciPy library, one component of the SciPy stack, providing many numerical routines.

# The SciPy ecosystem
## Scientific computing in Python builds upon a small core of packages:

* Python, a general purpose programming language. It is interpreted and dynamically typed and is very well suited for interactive work and quick prototyping, while being powerful enough to write large applications in.
* NumPy, the fundamental package for numerical computation. It defines the numerical array and matrix types and basic operations on them.
* The SciPy library, a collection of numerical algorithms and domain-specific toolboxes, including signal processing, optimization, statistics, and much more.
* Matplotlib, a mature and popular plotting package that provides publication-quality 2-D plotting, as well as rudimentary 3-D plotting.

On this base, the SciPy ecosystem includes general and specialised tools for data management and computation, productive experimentation, and high-performance computing. Below, we overview some key packages, though there are many more relevant packages.

## Data and computation:

* pandas, providing high-performance, easy-to-use data structures.
* SymPy, for symbolic mathematics and computer algebra.
* NetworkX, is a collection of tools for analyzing complex networks.
* scikit-image is a collection of algorithms for image processing.
* scikit-learn is a collection of algorithms and tools for machine learning.
* h5py and PyTables can both access data stored in the HDF5 format.

## Productivity and high-performance computing:

* IPython, a rich interactive interface, letting you quickly process data and test ideas.
* The Jupyter notebook provides IPython functionality and more in your web browser, allowing you to document your computation in an easily reproducible form.
* Cython extends Python syntax so that you can conveniently build C extensions, either to speed up critical code or to integrate with C/C++ libraries.
* Dask, Joblib or IPyParallel for distributed processing with a focus on numeric data.

## Quality assurance:

* nose, a framework for testing Python code, being phased out in preference for pytest.
* numpydoc, a standard and library for documenting Scientific Python libraries.

# NLP
Due to the popularity of NLP and hype in Data Science in recent years, there are many great NLP libraries developed and even the newbie data science enthusiasts started to play with various NLP techniques using these open source libraries. Here are the most popular NLP libraries that have been used heavily in the community and under various levels of development.

* Natural Language Toolkit (NLTK): The complete toolkit for all NLP techniques.
TextBlob: Easy to use NLP tools API, built on top of NLTK and Pattern.
* SpaCy: Industrial strength NLP with Python and Cython.
Gensim: Topic Modelling for Humans
* Stanford Core NLP: NLP services and packages by Stanford NLP Group.
* Fasttext: NLP library for the learning of word embeddings and sentence classification created by Facebookâ€™s AI Research (FAIR) lab